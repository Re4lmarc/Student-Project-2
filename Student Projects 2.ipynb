{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70503d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data preprocessing, visualization, dataset splitting\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea6af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0778444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76ad56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5172 entries, 0 to 5171\n",
      "Columns: 3002 entries, Email No. to Prediction\n",
      "dtypes: int64(3001), object(1)\n",
      "memory usage: 118.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_emails.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b66ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>5172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.640565</td>\n",
       "      <td>6.188128</td>\n",
       "      <td>5.143852</td>\n",
       "      <td>3.075599</td>\n",
       "      <td>3.124710</td>\n",
       "      <td>2.627030</td>\n",
       "      <td>55.517401</td>\n",
       "      <td>2.466551</td>\n",
       "      <td>2.024362</td>\n",
       "      <td>10.600155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.012568</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.098028</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.914733</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.290023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.745009</td>\n",
       "      <td>9.534576</td>\n",
       "      <td>14.101142</td>\n",
       "      <td>6.045970</td>\n",
       "      <td>4.680522</td>\n",
       "      <td>6.229845</td>\n",
       "      <td>87.574172</td>\n",
       "      <td>4.314444</td>\n",
       "      <td>6.967878</td>\n",
       "      <td>19.281892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.199682</td>\n",
       "      <td>0.116693</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>0.096252</td>\n",
       "      <td>0.138908</td>\n",
       "      <td>0.072145</td>\n",
       "      <td>2.780203</td>\n",
       "      <td>0.098086</td>\n",
       "      <td>0.453817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1898.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               the           to          ect          and          for  \\\n",
       "count  5172.000000  5172.000000  5172.000000  5172.000000  5172.000000   \n",
       "mean      6.640565     6.188128     5.143852     3.075599     3.124710   \n",
       "std      11.745009     9.534576    14.101142     6.045970     4.680522   \n",
       "min       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     1.000000     0.000000     1.000000   \n",
       "50%       3.000000     3.000000     1.000000     1.000000     2.000000   \n",
       "75%       8.000000     7.000000     4.000000     3.000000     4.000000   \n",
       "max     210.000000   132.000000   344.000000    89.000000    47.000000   \n",
       "\n",
       "                of            a          you          hou           in  ...  \\\n",
       "count  5172.000000  5172.000000  5172.000000  5172.000000  5172.000000  ...   \n",
       "mean      2.627030    55.517401     2.466551     2.024362    10.600155  ...   \n",
       "std       6.229845    87.574172     4.314444     6.967878    19.281892  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000    12.000000     0.000000     0.000000     1.000000  ...   \n",
       "50%       1.000000    28.000000     1.000000     0.000000     5.000000  ...   \n",
       "75%       2.000000    62.250000     3.000000     1.000000    12.000000  ...   \n",
       "max      77.000000  1898.000000    70.000000   167.000000   223.000000  ...   \n",
       "\n",
       "          connevey          jay       valued          lay  infrastructure  \\\n",
       "count  5172.000000  5172.000000  5172.000000  5172.000000     5172.000000   \n",
       "mean      0.005027     0.012568     0.010634     0.098028        0.004254   \n",
       "std       0.105788     0.199682     0.116693     0.569532        0.096252   \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "max       4.000000     7.000000     2.000000    12.000000        3.000000   \n",
       "\n",
       "          military     allowing           ff          dry   Prediction  \n",
       "count  5172.000000  5172.000000  5172.000000  5172.000000  5172.000000  \n",
       "mean      0.006574     0.004060     0.914733     0.006961     0.290023  \n",
       "std       0.138908     0.072145     2.780203     0.098086     0.453817  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     1.000000     0.000000     1.000000  \n",
       "max       4.000000     3.000000   114.000000     4.000000     1.000000  \n",
       "\n",
       "[8 rows x 3001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45dfbf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852715</td>\n",
       "      <td>0.337249</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.784112</td>\n",
       "      <td>0.796397</td>\n",
       "      <td>0.784451</td>\n",
       "      <td>0.471392</td>\n",
       "      <td>0.303621</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.075479</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.223426</td>\n",
       "      <td>0.101768</td>\n",
       "      <td>0.129466</td>\n",
       "      <td>0.127019</td>\n",
       "      <td>0.341878</td>\n",
       "      <td>0.051021</td>\n",
       "      <td>-0.004421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.852715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375480</td>\n",
       "      <td>0.825474</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>0.752722</td>\n",
       "      <td>0.896466</td>\n",
       "      <td>0.508513</td>\n",
       "      <td>0.347993</td>\n",
       "      <td>0.881759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.101247</td>\n",
       "      <td>0.232847</td>\n",
       "      <td>0.255793</td>\n",
       "      <td>0.093322</td>\n",
       "      <td>0.091639</td>\n",
       "      <td>0.120059</td>\n",
       "      <td>0.406666</td>\n",
       "      <td>0.071388</td>\n",
       "      <td>0.055277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ect</th>\n",
       "      <td>0.337249</td>\n",
       "      <td>0.375480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.369777</td>\n",
       "      <td>0.178028</td>\n",
       "      <td>0.400009</td>\n",
       "      <td>0.155783</td>\n",
       "      <td>0.974152</td>\n",
       "      <td>0.298387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134339</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>0.046080</td>\n",
       "      <td>0.061550</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>-0.007690</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.141460</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>-0.120782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.825474</td>\n",
       "      <td>0.272863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751287</td>\n",
       "      <td>0.809665</td>\n",
       "      <td>0.815196</td>\n",
       "      <td>0.476764</td>\n",
       "      <td>0.235953</td>\n",
       "      <td>0.874276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.104454</td>\n",
       "      <td>0.272963</td>\n",
       "      <td>0.253440</td>\n",
       "      <td>0.151980</td>\n",
       "      <td>0.084147</td>\n",
       "      <td>0.124766</td>\n",
       "      <td>0.400225</td>\n",
       "      <td>0.042484</td>\n",
       "      <td>0.114364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.784112</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>0.369777</td>\n",
       "      <td>0.751287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681457</td>\n",
       "      <td>0.744098</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>0.329051</td>\n",
       "      <td>0.762659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.236213</td>\n",
       "      <td>0.213631</td>\n",
       "      <td>0.134469</td>\n",
       "      <td>0.067151</td>\n",
       "      <td>0.121057</td>\n",
       "      <td>0.301074</td>\n",
       "      <td>0.038126</td>\n",
       "      <td>-0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.129466</td>\n",
       "      <td>0.091639</td>\n",
       "      <td>-0.007690</td>\n",
       "      <td>0.084147</td>\n",
       "      <td>0.067151</td>\n",
       "      <td>0.073004</td>\n",
       "      <td>0.111685</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>0.043408</td>\n",
       "      <td>0.104297</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055227</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.064850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allowing</th>\n",
       "      <td>0.127019</td>\n",
       "      <td>0.120059</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.124766</td>\n",
       "      <td>0.121057</td>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.105358</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>0.138099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002675</td>\n",
       "      <td>-0.003543</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.276001</td>\n",
       "      <td>0.055227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096212</td>\n",
       "      <td>-0.003995</td>\n",
       "      <td>0.011279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff</th>\n",
       "      <td>0.341878</td>\n",
       "      <td>0.406666</td>\n",
       "      <td>0.141460</td>\n",
       "      <td>0.400225</td>\n",
       "      <td>0.301074</td>\n",
       "      <td>0.444252</td>\n",
       "      <td>0.464473</td>\n",
       "      <td>0.195058</td>\n",
       "      <td>0.114210</td>\n",
       "      <td>0.448303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.073690</td>\n",
       "      <td>0.130356</td>\n",
       "      <td>0.164296</td>\n",
       "      <td>0.114092</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.096212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>0.135479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry</th>\n",
       "      <td>0.051021</td>\n",
       "      <td>0.071388</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.042484</td>\n",
       "      <td>0.038126</td>\n",
       "      <td>0.026403</td>\n",
       "      <td>0.093822</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.077751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003373</td>\n",
       "      <td>0.035028</td>\n",
       "      <td>-0.006468</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>-0.003137</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>-0.003995</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>-0.004421</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>-0.120782</td>\n",
       "      <td>0.114364</td>\n",
       "      <td>-0.003101</td>\n",
       "      <td>0.197234</td>\n",
       "      <td>0.107776</td>\n",
       "      <td>0.130293</td>\n",
       "      <td>-0.128340</td>\n",
       "      <td>0.154055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030375</td>\n",
       "      <td>-0.031694</td>\n",
       "      <td>0.098775</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>0.064850</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.135479</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows Ã— 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 the        to       ect       and       for        of  \\\n",
       "the         1.000000  0.852715  0.337249  0.841200  0.784112  0.796397   \n",
       "to          0.852715  1.000000  0.375480  0.825474  0.781971  0.752722   \n",
       "ect         0.337249  0.375480  1.000000  0.272863  0.369777  0.178028   \n",
       "and         0.841200  0.825474  0.272863  1.000000  0.751287  0.809665   \n",
       "for         0.784112  0.781971  0.369777  0.751287  1.000000  0.681457   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "military    0.129466  0.091639 -0.007690  0.084147  0.067151  0.073004   \n",
       "allowing    0.127019  0.120059  0.004368  0.124766  0.121057  0.108786   \n",
       "ff          0.341878  0.406666  0.141460  0.400225  0.301074  0.444252   \n",
       "dry         0.051021  0.071388  0.002492  0.042484  0.038126  0.026403   \n",
       "Prediction -0.004421  0.055277 -0.120782  0.114364 -0.003101  0.197234   \n",
       "\n",
       "                   a       you       hou        in  ...  connevey       jay  \\\n",
       "the         0.784451  0.471392  0.303621  0.845670  ...  0.008926  0.075479   \n",
       "to          0.896466  0.508513  0.347993  0.881759  ...  0.013250  0.101247   \n",
       "ect         0.400009  0.155783  0.974152  0.298387  ...  0.134339  0.031431   \n",
       "and         0.815196  0.476764  0.235953  0.874276  ...  0.005151  0.104454   \n",
       "for         0.744098  0.495852  0.329051  0.762659  ...  0.022168  0.041775   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "military    0.111685  0.006498  0.005429  0.120620  ... -0.002249 -0.002979   \n",
       "allowing    0.105358  0.082757 -0.000966  0.138099  ... -0.002675 -0.003543   \n",
       "ff          0.464473  0.195058  0.114210  0.448303  ...  0.005403  0.073690   \n",
       "dry         0.093822  0.028883  0.000601  0.077751  ... -0.003373  0.035028   \n",
       "Prediction  0.107776  0.130293 -0.128340  0.154055  ... -0.030375 -0.031694   \n",
       "\n",
       "              valued       lay  infrastructure  military  allowing        ff  \\\n",
       "the         0.225586  0.223426        0.101768  0.129466  0.127019  0.341878   \n",
       "to          0.232847  0.255793        0.093322  0.091639  0.120059  0.406666   \n",
       "ect         0.046080  0.061550        0.004393 -0.007690  0.004368  0.141460   \n",
       "and         0.272963  0.253440        0.151980  0.084147  0.124766  0.400225   \n",
       "for         0.236213  0.213631        0.134469  0.067151  0.121057  0.301074   \n",
       "...              ...       ...             ...       ...       ...       ...   \n",
       "military    0.043408  0.104297        0.041300  1.000000  0.055227  0.049524   \n",
       "allowing   -0.005130  0.018550        0.276001  0.055227  1.000000  0.096212   \n",
       "ff          0.130356  0.164296        0.114092  0.049524  0.096212  1.000000   \n",
       "dry        -0.006468  0.018939       -0.003137  0.010835 -0.003995  0.049690   \n",
       "Prediction  0.098775  0.064315        0.038161  0.064850  0.011279  0.135479   \n",
       "\n",
       "                 dry  Prediction  \n",
       "the         0.051021   -0.004421  \n",
       "to          0.071388    0.055277  \n",
       "ect         0.002492   -0.120782  \n",
       "and         0.042484    0.114364  \n",
       "for         0.038126   -0.003101  \n",
       "...              ...         ...  \n",
       "military    0.010835    0.064850  \n",
       "allowing   -0.003995    0.011279  \n",
       "ff          0.049690    0.135479  \n",
       "dry         1.000000   -0.006260  \n",
       "Prediction -0.006260    1.000000  \n",
       "\n",
       "[3001 rows x 3001 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd2cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_emails.drop(['Email No.', 'Prediction'], axis = 'columns')\n",
    "y = df_emails['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed395e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afe7cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create all model for prediction\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "knn_model = KNeighborsClassifier()\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "svm_model = SVC()\n",
    "NB_model = GaussianNB()\n",
    "NN_model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "436226a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d54aa5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.fit(X_train, y_train)\n",
    "dtree_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "NB_model.fit(X_train, y_train)\n",
    "NN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b8452e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_pred = logistic_model.predict(X_test)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "dtree_pred = dtree_model.predict(X_test)\n",
    "svmmodel_pred = svm_model.predict(X_test)\n",
    "NB_model_pred = NB_model.predict(X_test)\n",
    "NN_model_pred = NN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afb2a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLOGISTIC REGRESSION RESULT : \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1206\n",
      "           1       0.97      0.96      0.97       501\n",
      "\n",
      "    accuracy                           0.98      1707\n",
      "   macro avg       0.98      0.97      0.98      1707\n",
      "weighted avg       0.98      0.98      0.98      1707\n",
      "\n",
      "\u001b[1mKNN RESULT : \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1136\n",
      "           1       0.84      0.73      0.78       571\n",
      "\n",
      "    accuracy                           0.86      1707\n",
      "   macro avg       0.85      0.83      0.84      1707\n",
      "weighted avg       0.86      0.86      0.86      1707\n",
      "\n",
      "\u001b[1mDECISION TREE RESULT : \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1213\n",
      "           1       0.87      0.88      0.88       494\n",
      "\n",
      "    accuracy                           0.93      1707\n",
      "   macro avg       0.91      0.91      0.91      1707\n",
      "weighted avg       0.93      0.93      0.93      1707\n",
      "\n",
      "\u001b[1mSVM RESULT : \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87      1509\n",
      "           1       0.35      0.88      0.50       198\n",
      "\n",
      "    accuracy                           0.80      1707\n",
      "   macro avg       0.67      0.83      0.69      1707\n",
      "weighted avg       0.91      0.80      0.83      1707\n",
      "\n",
      "\u001b[1mNAIVE BAYES RESULT : \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1169\n",
      "           1       0.96      0.88      0.92       538\n",
      "\n",
      "    accuracy                           0.95      1707\n",
      "   macro avg       0.95      0.93      0.94      1707\n",
      "weighted avg       0.95      0.95      0.95      1707\n",
      "\n",
      "\u001b[1mNEURAL NETWORK RESULT : \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1197\n",
      "           1       0.99      0.96      0.98       510\n",
      "\n",
      "    accuracy                           0.99      1707\n",
      "   macro avg       0.99      0.98      0.98      1707\n",
      "weighted avg       0.99      0.99      0.99      1707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print classification report\n",
    "print(\"\\033[1m\" + \"LOGISTIC REGRESSION RESULT : \" + \"\\033[0m\")\n",
    "print(classification_report(logi_pred, y_test))\n",
    "\n",
    "print(\"\\033[1m\" + \"KNN RESULT : \" + \"\\033[0m\")\n",
    "print(classification_report(knn_pred, y_test))\n",
    "\n",
    "print(\"\\033[1m\" + \"DECISION TREE RESULT : \" + \"\\033[0m\")\n",
    "print(classification_report(dtree_pred, y_test))\n",
    "\n",
    "print(\"\\033[1m\" + \"SVM RESULT : \" + \"\\033[0m\")\n",
    "print(classification_report(svmmodel_pred, y_test))\n",
    "\n",
    "print(\"\\033[1m\" + \"NAIVE BAYES RESULT : \"  + \"\\033[0m\")\n",
    "print(classification_report(NB_model_pred, y_test))\n",
    "\n",
    "print(\"\\033[1m\" + \"NEURAL NETWORK RESULT : \" + \"\\033[0m\")\n",
    "print(classification_report(NN_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a0f74",
   "metadata": {},
   "source": [
    "Dari hasil yang didapat untuk 6 model yang dilakukan pengujian\n",
    "jika diurut secara ranking, model dengan akurasi dan F1 terbaik didapatkan oleh\n",
    "\n",
    "1) Neural Network (accuracy = 99%, F1 Score 0 : 99%, F1 Score 1 : 98%)\n",
    "\n",
    "2) Logistic Regression (accuracy = 98%, F1 Score 0 : 99%, F1 Score 1 : 97%)\n",
    "\n",
    "3) Naive Bayes (accuracy = 95%, F1 Score 0 : 96%, F1 Score 1 : 92%) \n",
    "\n",
    "4) Decision Tree (accuracy = 93%, F1 Score 0 : 95%, F1 Score 1 : 88%)\n",
    "\n",
    "5) K-Nearest Neighbors (accuracy = 86%, F1 Score 0 : 90%, F1 Score 1 : 78%)\n",
    "\n",
    "6) Support Vector Machine (SVM) (accuracy = 80%, F1 Score 0 : 87%, F1 Score 1 : 50%)\n",
    "\n",
    "secara model performance (tanpa tuning parameter), hasil terbaik diraih oleh neural network, tapi melihat peringkat ke 2 dengan akurasi dan F1 score yang tidak jauh berbeda logistic regression juga merupakan pilihan yang baik dalam implementasi model dikarenakan konsep penghitungan neural network yang cukup rumit dan computational power yang tinggi untuk melakukan implementasi dari model neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
